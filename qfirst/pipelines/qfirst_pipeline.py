 # completely ridiculous hack to import stuff properly. somebody save me from myself
import importlib
from allennlp.common.util import import_submodules
importlib.invalidate_caches()
import sys
sys.path.append(".")
import_submodules("qfirst")

from typing import List, Iterator, Optional

import torch, os, json, tarfile, argparse, uuid, shutil
import sys

from overrides import overrides

from allennlp.common.util import lazy_groups_of
from allennlp.common.checks import check_for_gpu, ConfigurationError
from allennlp.common.util import JsonDict, sanitize
from allennlp.common.util import get_spacy_model
from allennlp.data import Instance
from allennlp.data.dataset import Batch
from allennlp.data.fields import ListField, SpanField, LabelField
from allennlp.nn.util import move_to_device
from allennlp.data import DatasetReader, Instance
from allennlp.models import Model
from allennlp.models.archival import load_archive
from allennlp.predictors.predictor import JsonDict, Predictor

from allennlp.common.file_utils import cached_path
from qfirst.data.util import read_lines, get_verb_fields, get_slot_label_namespace

from qfirst.data.dataset_readers import QasrlReader
from qfirst.models.qfirst.qfirst_question_answerer import QfirstQuestionAnswerer
from qfirst.models.qfirst.qfirst_question_generator import QfirstQuestionGenerator

span_minimum_threshold_default = 0.05
question_minimum_threshold_default = 0.05
question_beam_size_default = 10

class QfirstPipeline():
    def __init__(self,
                 question_generator: QfirstQuestionGenerator,
                 question_generator_dataset_reader: QasrlReader,
                 question_answerer: QfirstQuestionAnswerer,
                 question_answerer_dataset_reader: QasrlReader,
                 span_minimum_threshold: float = span_minimum_threshold_default,
                 question_minimum_threshold: float = question_minimum_threshold_default,
                 question_beam_size: int = question_beam_size_default,
                 clause_mode: bool = False) -> None:
        self._question_generator = question_generator
        self._question_generator_dataset_reader = question_generator_dataset_reader
        self._question_answerer = question_answerer
        self._question_answerer_dataset_reader = question_answerer_dataset_reader
        self._span_minimum_threshold = span_minimum_threshold
        self._question_minimum_threshold = question_minimum_threshold
        self._question_beam_size = question_beam_size
        self._clause_mode = clause_mode # TODO implement the logic for this

        qg_slots = set(self._question_generator.get_slot_names())
        qa_slots = set(self._question_answerer.get_slot_names())
        if not qa_slots.issubset(qg_slots):
            raise ConfigurationError(
                "Question Answerer must read in a subset of question slots generated by the Question Generator.\n" + \
                ("QG slots: %s\nQA slots: %s" % (qg_slots, qa_slots)))

    def predict(self, inputs: JsonDict) -> JsonDict:
        question_generator_verb_instances = list(self._question_generator_dataset_reader.sentence_json_to_instances(inputs, verbs_only = True))
        question_answerer_verb_instances = list(self._question_answerer_dataset_reader.sentence_json_to_instances(inputs, verbs_only = True))
        verb_dicts = []
        for (qg_verb_instance, qa_verb_instance) in zip(question_generator_verb_instances, question_answerer_verb_instances):
            qg_verb_instance.index_fields(self._question_generator.vocab)
            qgen_input_tensors = move_to_device(
                Batch([qg_verb_instance]).as_tensor_dict(),
                self._question_generator._get_prediction_device())
            _, all_question_slots, question_probs = self._question_generator.beam_decode(
                text = qgen_input_tensors["text"],
                predicate_indicator = qgen_input_tensors["predicate_indicator"],
                predicate_index = qgen_input_tensors["predicate_index"],
                max_beam_size = self._question_beam_size,
                min_beam_probability = self._question_minimum_threshold)
            beam = []
            for i in range(len(question_probs)):
                question_slots = {}
                for slot_name in self._question_answerer.get_slot_names():
                    slot_label = all_question_slots[slot_name][i]
                    question_slots[slot_name] = slot_label
                    slot_label_field = LabelField(slot_label, get_slot_label_namespace(slot_name))
                    qa_verb_instance.add_field(slot_name, slot_label_field, self._question_answerer.vocab)
                qa_output = self._question_answerer.forward_on_instance(qa_verb_instance)
                scored_spans = [(s, p) for s, p in qa_output["spans"] if p >= self._span_minimum_threshold]
                invalid_dict = {}
                if self._question_answerer.classifies_invalids:
                    invalid_dict["invalidProb"] = qa_output["invalid_prob"].item()
                for span, span_prob in scored_spans:
                    beam.append({
                        "questionSlots": question_slots,
                        "questionProb": question_probs[i],
                        **invalid_dict,
                        "span": [span.start(), span.end() + 1],
                        "spanProb": span_prob
                    })
            verb_dicts.append({
                "verbIndex": qa_verb_instance["metadata"]["verb_index"],
                "verbInflectedForms": qa_verb_instance["metadata"]["verb_inflected_forms"],
                "beam": beam
            })
        return {
            "sentenceId": inputs["sentenceId"],
            "sentenceTokens": inputs["sentenceTokens"],
            "verbs": verb_dicts
        }

def main(question_generator_path: str,
         question_answerer_path: str,
         cuda_device: int,
         input_file: str,
         output_file: str,
         span_min_prob: float,
         question_min_prob: float,
         question_beam_size: int,
         clause_mode: bool) -> None:
    check_for_gpu(cuda_device)
    question_generator_archive = load_archive(question_generator_path, cuda_device = cuda_device)
    question_answerer_archive = load_archive(question_answerer_path, cuda_device = cuda_device)
    pipeline = QfirstPipeline(
        question_generator = question_generator_archive.model,
        question_generator_dataset_reader = DatasetReader.from_params(question_generator_archive.config["dataset_reader"].duplicate()),
        question_answerer = question_answerer_archive.model,
        question_answerer_dataset_reader = DatasetReader.from_params(question_answerer_archive.config["dataset_reader"].duplicate()),
        span_minimum_threshold = span_min_prob,
        question_minimum_threshold = question_min_prob,
        question_beam_size = question_beam_size,
        clause_mode = clause_mode)
    if output_file is None:
        for line in read_lines(cached_path(input_file)):
            input_json = json.loads(line)
            output_json = pipeline.predict(input_json)
            print(json.dumps(output_json))
    else:
        with open(output_file, 'w', encoding = 'utf8') as out:
            for line in read_lines(cached_path(input_file)):
                input_json = json.loads(line)
                output_json = pipeline.predict(input_json)
                print(json.dumps(output_json), file = out)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description = "Run the answer-first pipeline")
    parser.add_argument('--question_generator', type=str, help = "Path to question generator model archive (.tar.gz).")
    parser.add_argument('--question_answerer', type=str, help = "Path to question answerer model archive (.tar.gz).")
    parser.add_argument('--cuda_device', type=int, default=-1)
    parser.add_argument('--input_file', type=str)
    parser.add_argument('--output_file', type=str, default = None)
    parser.add_argument('--span_min_prob', type=float, default = span_minimum_threshold_default)
    parser.add_argument('--question_min_prob', type=float, default = question_minimum_threshold_default)
    parser.add_argument('--question_beam_size', type=int, default = question_beam_size_default)
    parser.add_argument('--clause_mode', type=bool, default = False)

    args = parser.parse_args()
    main(question_generator_path = args.question_generator,
         question_answerer_path = args.question_answerer,
         cuda_device = args.cuda_device,
         input_file = args.input_file,
         output_file = args.output_file,
         span_min_prob = args.span_min_prob,
         question_min_prob = args.question_min_prob,
         question_beam_size = args.question_beam_size,
         clause_mode = args.clause_mode)
