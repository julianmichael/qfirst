from typing import Dict, List

from overrides import overrides

import torch

from allennlp.common.util import JsonDict, sanitize
from allennlp.common.util import get_spacy_model
from allennlp.data.dataset import Batch
from allennlp.data.fields import ListField, SpanField, LabelField
from allennlp.nn.util import move_to_device
from allennlp.data import DatasetReader, Instance
from allennlp.models import Model
from allennlp.predictors.predictor import Predictor

from qfirst.common.span import Span
from qfirst.data.dataset_readers import QasrlReader
from qfirst.data.util import get_slot_label_namespace
from qfirst.models.qfirst.qfirst_parser import QfirstParser

# should receive verb instances from the qasrl dataset reader
@Predictor.register("qfirst")
class QfirstPredictor(Predictor):
    def __init__(self,
                 model: QfirstParser,
                 dataset_reader: QasrlReader,
                 question_beam_size: int = 20,
                 question_minimum_prob: float = 0.01,
                 span_minimum_prob: float = 0.01,
                 clause_mode: bool = False):
        super(QfirstPredictor, self).__init__(model, dataset_reader)
        self._question_beam_size = question_beam_size
        self._question_minimum_prob = question_minimum_prob
        self._span_minimum_prob = span_minimum_prob
        self._clause_mode = clause_mode

        qg_slots = set(self._model.get_question_generator().get_slot_names())
        qa_slots = set(self._model.get_question_answerer().get_slot_names())
        if not qa_slots.issubset(qg_slots):
            raise ConfigurationError(
                "Question Answerer must read in a subset of question slots generated by the Question Generator.\n" + \
                ("QG slots: %s\nQA slots: %s" % (qg_slots, qa_slots)))

    @overrides
    def predict_json(self, inputs: JsonDict) -> JsonDict:
        verb_instances = list(self._dataset_reader.sentence_json_to_instances(inputs, verbs_only = True))
        verb_dicts = []
        for verb_instance in verb_instances:
            verb_instance.index_fields(self._model.vocab)
            qgen_input_tensors = move_to_device(
                Batch([verb_instance]).as_tensor_dict(),
                self._model.get_question_generator()._get_prediction_device())
            _, all_question_slots, question_probs = self._model.get_question_generator().beam_decode(
                text = qgen_input_tensors["text"],
                predicate_indicator = qgen_input_tensors["predicate_indicator"],
                predicate_index = qgen_input_tensors["predicate_index"],
                max_beam_size = self._question_beam_size,
                min_beam_probability = self._question_minimum_prob)
            beam = []
            for i in range(len(question_probs)):
                question_slots = {}
                for slot_name in self._model.get_question_answerer().get_slot_names():
                    slot_label = all_question_slots[slot_name][i]
                    question_slots[slot_name] = slot_label
                    slot_label_field = LabelField(slot_label, get_slot_label_namespace(slot_name))
                    verb_instance.add_field(slot_name, slot_label_field, self._model.vocab)
                span_output = self._model.get_question_answerer().forward_on_instance(verb_instance)
                scored_spans = [(s, p) for s, p in span_output["spans"] if p >= self._span_minimum_prob]
                for span, span_prob in scored_spans:
                    beam.append({
                        "question_slots": question_slots,
                        "question_prob": question_probs[i],
                        "span": [span.start(), span.end() + 1],
                        "span_prob": span_prob
                    })
            verb_dicts.append({
                "verbIndex": verb_instance["metadata"]["verb_index"],
                "verbInflectedForms": verb_instance["metadata"]["verb_inflected_forms"],
                "beam": beam
            })
        return {
            "sentenceId": inputs["sentenceId"],
            "sentenceTokens": inputs["sentenceTokens"],
            "verbs": verb_dicts
        }

    @overrides
    def predict_batch_json(self, inputs: List[JsonDict]) -> List[JsonDict]:
        return map(inputs, self.predict_json)
